{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b90dae47-a181-40d3-bc41-fdd943304bb7",
   "metadata": {},
   "source": [
    "# Create Fake Binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae1a4d7e-8fcf-4193-8b10-c88f6c11d7bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'build_synthetic_set'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbuild_synthetic_set\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mastropy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Table\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'build_synthetic_set'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.insert(1, '/Users/azib/Documents/open_source/nets2/stella/')\n",
    "sys.path.insert(1, '/Users/azib/Documents/open_source/nets2/scripts/')\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import build_synthetic_set as models\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import wotan\n",
    "import lightkurve as lk\n",
    "import stella\n",
    "import pandas as pd\n",
    "import random\n",
    "import batman\n",
    "import warnings\n",
    "from astroquery.mast import Catalogs\n",
    "import astropy.constants as const\n",
    "import time as ti\n",
    "import re\n",
    "import pickle\n",
    "import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a01e83-531d-4d44-8038-0df70a760144",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('../data/eleanor/s0007/*.fits', recursive=True)\n",
    "random.shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4db5836-6292-45d0-badc-e3c666a8eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'bianries1k-new'\n",
    "folder = f'../models/{name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b2dab-2396-4559-8b22-65b185025ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeout_handler(signum, frame):\n",
    "    raise TimeoutError(\"Timeout reached.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66343ec1-c6bf-4e9f-a614-709b9b3b25dd",
   "metadata": {},
   "source": [
    "### Load the star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1d3ea5-201d-4b52-818c-b12a055571f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_IDs = [int(re.search(r\"(\\d{16})\", filename).group(1).lstrip('0')) for filename in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af670162-9288-4f22-8ee8-19cbfda80410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the minimum and maximum periods\n",
    "# period_min = 2\n",
    "# period_max = 700.0\n",
    "\n",
    "# # Generate random values from a uniform distribution between log10(period_min) and log10(period_max)\n",
    "# num_planets = 5000  # Larger number for better visualization\n",
    "# log_periods = np.random.uniform(np.log10(period_min), np.log10(period_max), size=num_planets)\n",
    "\n",
    "# # Convert the log-scale values back to linear scale\n",
    "# periods = 10 ** log_periods\n",
    "\n",
    "# # Plot the histogram\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.hist(periods, bins=50, edgecolor='black')\n",
    "# plt.xlabel('Period (days)')\n",
    "\n",
    "# plt.title('Log Uniform Distribution')\n",
    "# plt.xlim(period_min, period_max)\n",
    "# plt.savefig('log-dist.png',dpi=200)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ad493-fc00-42d9-ad69-e85afb6c9359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_timestep(table):\n",
    "    \"\"\"\n",
    "    Function: Calculates the median value of the time differences between data points in a given table. \n",
    "    Provides an estimate of the timestep (or time delta) between consecutive data points.\n",
    "\n",
    "    Parameters:\n",
    "    :table (array or pandas.DataFrame): The input table containing time-series data.\n",
    "\n",
    "    Returns:\n",
    "    :dt (float): The estimated time interval or timestep between consecutive data points.\"\"\"\n",
    "\n",
    "    try:\n",
    "        dt = [ table[i+1][0] - table[i][0] for i in range(len(table)-1) ] # calculates difference between (ith+1) - (ith) point \n",
    "        dt.sort()\n",
    "        return dt[int(len(dt)/2)] # median of them.\n",
    "    except:\n",
    "        return np.median(np.diff(table['time'])) ## change this to account for any time column names\n",
    "\n",
    "    \n",
    "\n",
    "def clean_data(table):\n",
    "    \"\"\"\n",
    "    Function: Interpolating missing data points, ensuring equal time gaps between points. \n",
    "    Returns five numpy arrays: time, flux, quality, real, and flux_error. Real is 0 if data point interpolated, 1 otherwise.\n",
    "\n",
    "    Parameters:\n",
    "    :table (astropy.table.table): The input table containing time-series data.\n",
    "    \n",
    "    Returns:\n",
    "    :time (numpy.ndarray): An array of timestamps for each data point, including the interpolated points.\n",
    "    :flux (numpy.ndarray): An array of flux values for each data point, including the interpolated points.\n",
    "    :quality (numpy.ndarray): An array indicating the quality of each data point, including the interpolated points.\n",
    "    :real (numpy.ndarray): An array indicating whether each data point is real (1) or interpolated (0).\n",
    "    :flux_error (numpy.ndarray): An array of flux error values for each data point, including the interpolated points.\"\"\"\n",
    "\n",
    "\n",
    "    time = []\n",
    "    flux = []\n",
    "    quality = []\n",
    "    real = []\n",
    "    flux_error = []\n",
    "    timestep = calculate_timestep(table)\n",
    "\n",
    "\n",
    "    ### this scale factor ensures that you can use any cadence of lightcurves. 48 cadences = 1 day.\n",
    "    factor = ((1/48)/timestep)\n",
    "\n",
    "    for row in table:\n",
    "        ti, fi, qi, fei = row\n",
    "\n",
    "        if len(time) > 0:\n",
    "            steps = int(round( (ti - time[-1])/timestep * factor)) # (y2-y1)/(x2-x1)\n",
    "            if steps > 1:\n",
    "                fluxstep = (fi - flux[-1])/steps\n",
    "                fluxerror_step = (fei - flux_error[-1])/steps\n",
    "\n",
    "                # For small gaps, pretend interpolated data is real.\n",
    "                if steps > 2:\n",
    "                    set_real=0\n",
    "                else:\n",
    "                    set_real=1\n",
    "\n",
    "                for _ in range(steps-1):\n",
    "                    time.append(timestep + time[-1])\n",
    "                    flux.append(fluxstep + flux[-1])\n",
    "                    flux_error.append(fluxerror_step + flux_error[-1])\n",
    "\n",
    "                    quality.append(0)\n",
    "                    real.append(set_real)\n",
    "        time.append(ti)\n",
    "        flux.append(fi)\n",
    "        quality.append(qi)\n",
    "        real.append(1)\n",
    "        flux_error.append(fei)\n",
    "\n",
    "    return [np.array(x) for x in [time,flux,quality,real,flux_error]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227d011-1c2e-4dfd-bd7e-7a10d044f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the power law exponent (alpha)\n",
    "# Larger values of alpha will skew the distribution more towards shorter periods\n",
    "alpha = 1.6\n",
    "\n",
    "# Define the minimum and maximum periods\n",
    "period_min = 15\n",
    "period_max = 700.0\n",
    "\n",
    "periods = []\n",
    "for _ in range(5000):\n",
    "    random_value = np.random.uniform(0, 1)\n",
    "    period = period_min * (period_max / period_min) ** (random_value ** (1 / alpha))\n",
    "    periods.append(period)\n",
    "\n",
    "num_planets = 1\n",
    "max_retries = 5\n",
    "retry_delay = 1\n",
    "timeout_duration = 5\n",
    "\n",
    "TIC_table = Catalogs.query_object(f'TIC 270577175', catalog=\"TIC\")\n",
    "r_star = TIC_table['rad'][0]\n",
    "m_star = TIC_table['mass'][0]\n",
    "\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(periods, bins=30,  alpha=0.6, edgecolor='black')\n",
    "plt.xlabel('Orbital Period (days)')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title(f'Distribution of Orbital Periods (alpha={alpha})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565443fd-9a22-4a8a-a1b4-59ef367ca20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and parameters\n",
    "min_snr = 3\n",
    "max_snr = 20\n",
    "window_size = 84\n",
    "max_retries = 20\n",
    "timeout_duration = 30  # Adjust as needed\n",
    "retry_delay = 1  # Adjust as needed\n",
    "\n",
    "times = []\n",
    "ticid = []\n",
    "snr = []\n",
    "p = []\n",
    "rms_cat = []\n",
    "\n",
    "for target_ID in tqdm(files[0:1000]):\n",
    "    try:\n",
    "        # Read in lightcurve\n",
    "        lc, lc_info = import_lightcurve(target_ID, drop_bad_points=True)\n",
    "        sector = f\"{lc_info['sector']:02d}\"\n",
    "        tic = lc_info['TIC_ID']\n",
    "\n",
    "        # Flatten the original lightcurve\n",
    "        flat_flux = wotan.flatten(lc['TIME'], lc['PCA_FLUX'], method='median', window_length=1)\n",
    "\n",
    "        # Get RMS of flattened original lightcurve\n",
    "        rms = np.nanstd(flat_flux)\n",
    "        if np.isnan(rms):\n",
    "            continue\n",
    "\n",
    "        # Identify large gaps in original lightcurve\n",
    "        diff = np.diff(lc['TIME'])\n",
    "        large_gaps_indices = np.where(diff > 1)[0]\n",
    "\n",
    "        # Create copy of lightcurve and clean data\n",
    "        lcc = lc.copy()\n",
    "        lcc = lcc[lcc['QUALITY'] == 0]\n",
    "        lcc = lcc['TIME', 'PCA_FLUX', 'QUALITY', 'FLUX_ERR']\n",
    "        time, flux, quality, real, flux_error = clean_data(lcc)\n",
    "\n",
    "        # Choose random SNR value and calculate amplitude\n",
    "        random_snr = np.random.uniform(min_snr, max_snr)\n",
    "        A = rms * random_snr\n",
    "\n",
    "        valid_model_found = False\n",
    "        retry_count = 0\n",
    "\n",
    "        while not valid_model_found and retry_count < max_retries:\n",
    "            signal.signal(signal.SIGALRM, timeout_handler)\n",
    "            signal.alarm(timeout_duration)\n",
    "\n",
    "            try:\n",
    "                # Find valid injection time\n",
    "                valid_time_found = False\n",
    "                while not valid_time_found:\n",
    "                    t0 = np.random.uniform(lc['TIME'][0], lc['TIME'][-1])\n",
    "                    \n",
    "                    # Check if t0 avoids large gaps\n",
    "                    valid_t0 = True\n",
    "                    for index in large_gaps_indices:\n",
    "                        start_time = lc['TIME'][index] - 1\n",
    "                        end_time = lc['TIME'][index + 1] + 1\n",
    "                        if start_time <= t0 <= end_time:\n",
    "                            valid_t0 = False\n",
    "                            break\n",
    "                        elif index < len(lc['TIME']) - 1 and diff[index] > 0.5 and abs(t0 - lc['TIME'][index + 1]) < 1.5:\n",
    "                            valid_t0 = False\n",
    "                            break\n",
    "                        elif index > 0 and diff[index - 1] > 0.5 and abs(t0 - lc['TIME'][index]) < 1.5:\n",
    "                            valid_t0 = False\n",
    "                            break\n",
    "                        elif t0 <= lc['TIME'][0] + 2 or t0 >= lc['TIME'][-1] - 2:\n",
    "                            valid_t0 = False\n",
    "                            break\n",
    "\n",
    "                    if valid_t0:\n",
    "                        # Check if all data points within the window are non-interpolated\n",
    "                        window_start = np.argmin(np.abs(time - (t0 - window_size * np.median(np.diff(time)))))\n",
    "                        window_end = np.argmin(np.abs(time - (t0 + window_size * np.median(np.diff(time))))) + 1\n",
    "                        if np.all(real[window_start:window_end] == 1):\n",
    "                            valid_time_found = True\n",
    "\n",
    "                # Create transit model\n",
    "                params = batman.TransitParams()\n",
    "                params.t0 = t0\n",
    "                random_value = np.random.uniform(0, 1)\n",
    "                params.per = period_min * (period_max / period_min) ** (random_value ** (1 / alpha))\n",
    "                p.append(params.per)\n",
    "                params.rp = np.sqrt(A)\n",
    "                params.a = ((params.per * 86400.) ** 2 * const.G.value * m_star * const.M_sun.value / \n",
    "                            (4 * np.pi**2)) ** (1/3) / (r_star * const.R_sun.value)\n",
    "                params.inc = 90\n",
    "                params.ecc = 0\n",
    "                params.w = 90\n",
    "                params.limb_dark = \"linear\"\n",
    "                params.u = [np.random.uniform(0.1, 1)]  # Linear limb darkening coefficient\n",
    "\n",
    "                m = batman.TransitModel(params, time, fac=0.02)\n",
    "                model = m.light_curve(params)\n",
    "\n",
    "                # Inject model into lightcurve\n",
    "                injected_flux = model * (flux / np.nanmedian(flux))\n",
    "                \n",
    "                ### NORMALISE INJECTED_FLUX\n",
    "                f = injected_flux - 1 \n",
    "                f = f/np.nanstd(f)\n",
    "                f = 1 + f\n",
    "                injected_flux = (f - np.min(f)) / (np.max(f) - np.min(f))\n",
    "\n",
    "                if np.all(injected_flux >= 0):\n",
    "                    valid_model_found = True\n",
    "                else:\n",
    "                    retry_count += 1\n",
    "\n",
    "            except TimeoutError:\n",
    "                retry_count += 1\n",
    "            except Exception as e:\n",
    "                if \"Convergence failure\" in str(e):\n",
    "                    retry_count += 1\n",
    "                else:\n",
    "                    raise e\n",
    "            finally:\n",
    "                signal.alarm(0)\n",
    "\n",
    "        if not valid_model_found:\n",
    "            print(f\"Failed to create a valid model for file {target_ID} after {max_retries} attempts. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Save injected lightcurve\n",
    "        fluxerror = flux_error / np.nanmedian(flux)\n",
    "        np.save(f\"{folder}/{tic}_sector{sector}.npy\", \n",
    "                np.array([time[real == 1], injected_flux[real == 1], fluxerror[real == 1], real[real == 1], model[real == 1]]))\n",
    "\n",
    "        # Update catalogs\n",
    "        times.append(t0)\n",
    "        ticid.append(tic)\n",
    "        snr.append(random_snr)\n",
    "        rms_cat.append(rms)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred for file {target_ID}: {e}. Continuing...\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d3189-d333-4c50-b88d-9ca581b2a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data=[ticid,times]).T\n",
    "data.columns = ['TIC','tpeak']\n",
    "data.TIC = data.TIC.astype(int)\n",
    "table = Table.from_pandas(data)\n",
    "\n",
    "table.write(f'../catalogs/{name}.txt', format='ascii', overwrite=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f472c68-5239-48bc-8f0b-e63043708a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = stella.FlareDataSet(fn_dir=f'/Users/azib/Documents/open_source/nets2/models/{name}',\n",
    "                         catalog=f'/Users/azib/Documents/open_source/nets2/catalogs/{name}.txt',cadences=168,training=0.8,validation=0.9,merge_datasets=False,frac_balance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916bb0cc-df0b-4ca7-bab5-01819b9deeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_pc = np.where(ds.train_labels==1)[0] # Flares\n",
    "ind_nc = np.where(ds.train_labels==0)[0] # No flares\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10,3),\n",
    "                               sharex=True, sharey=True)\n",
    "ax1.plot(ds.train_data[ind_pc[0]], 'r')\n",
    "ax1.set_title('Planet')\n",
    "ax1.set_xlabel('Cadences')\n",
    "ax2.plot(ds.train_data[ind_nc[0]], 'k')\n",
    "ax2.set_title('No Planet')\n",
    "ax2.set_xlabel('Cadences');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c097c32d-a79a-4915-8779-2f36f982915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('binary-models/',exist_ok=True)\n",
    "dsmodels = ds.train_data[ind_pc]\n",
    "num_sets = dsmodels.shape[0] // 100\n",
    "\n",
    "for set_index in tqdm(range(num_sets)):\n",
    "    start_index = set_index * 100\n",
    "    end_index = min((set_index + 1) * 100, dsmodels.shape[0])  # Ensure not to exceed the length of the data\n",
    "\n",
    "    # Create a new 10x10 grid of subplots for each set\n",
    "    fig, axs = plt.subplots(10, 10, figsize=(20, 20))\n",
    "\n",
    "    # Flatten the axes array for easier iteration\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Iterate over the elements in the current set and plot each in the grid\n",
    "    for i in range(start_index, end_index):\n",
    "        plot_index = i % 100  # Calculate the index within the current grid\n",
    "        axs[plot_index].plot(dsmodels[i, :, 0])  # Assuming you want to plot the first dimension of your array\n",
    "        axs[plot_index].set_title(f\"Plot {i+1}\")  # Title for each subplot\n",
    "\n",
    "    # Hide any remaining empty subplots\n",
    "    for j in range(end_index - start_index, len(axs)):\n",
    "        axs[j].axis('off')\n",
    "\n",
    "    \n",
    "    plt.tight_layout()  # Adjust layout\n",
    "    plt.savefig(f'binary-models/binary-models{start_index}-{end_index}.png',dpi=200)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nets2",
   "language": "python",
   "name": "nets2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
